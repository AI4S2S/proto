{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Teleconnections (precursor regions) via correlation maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, inspect\n",
    "main_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))) # script directory\n",
    "print(main_dir)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from RGCPD import RGCPD\n",
    "from RGCPD import BivariateMI\n",
    "import class_BivariateMI, functions_pp\n",
    "import numpy as np\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGCPD docstring\n",
    "Class to study teleconnections of a Response Variable* of interest.\n",
    "\n",
    "    Methods to extract teleconnections/precursors:\n",
    "        - BivariateMI (supporting (partial) correlation maps)\n",
    "        - EOF analysis\n",
    "\n",
    "    BivariateMI (MI = Mutual Information) is class which allows for a\n",
    "    statistical test in the form:\n",
    "    MI(lon,lat) = for gc in map: func(x(t), y(t)),\n",
    "    where map is a (time,lon,lat) map and gc stands for each gridcell/coordinate\n",
    "    in that map. The y timeseries is always the same 1-dimensional timeseries of\n",
    "    interest (i.e. the Response Variable). At this point, only supports the\n",
    "    correlation analysis. Once the significance is attributed, it is stored\n",
    "    in the MI map. Precursor regions are found by clustering the\n",
    "    significantly (correlating) gridcells (+ and - regions are separated)\n",
    "    and extract their spatial mean (or spatial covariance) timeseries.\n",
    "\n",
    "    *Sometimes Response Variable is also called Target Variable.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_name_path : list, optional\n",
    "        list of (name, path) tuples defining the input data.\n",
    "\n",
    "        Convention: first entry should be (name, path) of target variable (TV).\n",
    "        e.g. list_of_name_path = [('TVname', 'TVpath'), ('prec_name', 'prec_path')]\n",
    "\n",
    "        TVpath input data supports .nc/.h5 or .csv file format.\n",
    "        if using output of the clustering:\n",
    "            'TVname' should refer the name\n",
    "            you have given the timeseries on the dimesion 'cluster', i.e.\n",
    "            xrTV.sel(cluster=TVname)\n",
    "        elif using .h5 the index should contain a datetime axis.\n",
    "        elif using .csv the first columns should be [year, month, day, value]\n",
    "\n",
    "\n",
    "        prec_path input data supports only .nc\n",
    "        'prec_name' is a string/key that can be chosen freely, does not have\n",
    "        to refer to the variable in the .nc file.\n",
    "        Each prec_path .nc file should contain only a single variable\n",
    "        of format (time, lat, lon).\n",
    "    list_for_EOFS : list, optional\n",
    "        list of EOF classes, see docs EOF?\n",
    "    list_import_ts : list, optional\n",
    "        Load in precursor 1-d timeseries in format:\n",
    "        [(name1, path_to_h5_file1), [(name2, path_to_h5_file2)]]\n",
    "        precursor_ts can handle the RGCPD cross-validation format.\n",
    "    start_end_TVdate : tuple, optional\n",
    "        tuple of start- and enddate for target variable in\n",
    "        format ('mm-dd', 'mm-dd').\n",
    "    tfreq : int, optional\n",
    "        The default is 10, if using time_mean_periods, tfreq should be None.\n",
    "    start_end_date : tuple, optional\n",
    "        tuple of start- and enddate for data to load in\n",
    "        format ('mm-dd', 'mm-dd'). default is ('01-01' - '12-31')\n",
    "    start_end_year : tuple, optional\n",
    "        default is to load all years\n",
    "    path_outmain : [str, bool], optional\n",
    "        Root folder for output. If None, default is your\n",
    "        '/users/{username}/Download' path.\n",
    "    append_pathsub: str, optional\n",
    "        The first subfolder will be created below path_outmain, to store\n",
    "        output data & figures. The append_pathsub1 argument allows you to\n",
    "        manually add some hash or string refering to some experiment.\n",
    "    save : bool, optional\n",
    "        If you want to save figures, data and text output automatically.\n",
    "    verbosity : int, optional\n",
    "        Regulate the amount of feedback given by the code.\n",
    "        The default is 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    initialization of the RGCPD class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = os.path.join(main_dir, 'data') # path of test data\n",
    "# define input by filling list_of_name_path: \n",
    "# format list_of_name_path = [('TVname', 'TVpath'), ('prec_name', 'prec_path')]\n",
    "list_of_name_path = [(3, os.path.join(path_test, 'tf5_nc5_dendo_80d77.nc')),\n",
    "                    ('sst', os.path.join(path_test,'sst_daily_1979-2018_5deg_Pacific_175_240E_25_50N.nc'))]\n",
    "\n",
    "# define analysis:\n",
    "list_for_MI = [BivariateMI(name='sst', func=class_BivariateMI.corr_map, \n",
    "                           alpha=.01, FDR_control=True, lags=np.array([1]), \n",
    "                           distance_eps=700, min_area_in_degrees2=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?BivariateMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-handling subseasonal mode (DJF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = RGCPD(list_of_name_path=list_of_name_path,\n",
    "           list_for_MI=list_for_MI,\n",
    "           tfreq=10, # <- subseasonal forecasting mode, all data will be aggregated to 10-day means\n",
    "           start_end_TVdate=('02-28', '12-01'), # <- defining DJF target period \n",
    "           start_end_date=('02-28', '07-01'), # <- Loading subset of data for computational efficiency\n",
    "           path_outmain=os.path.join(main_dir,'data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"./data/subseasonal_mode_DJF.png\", width = 400, height = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-handling subseasonal mode (JJA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = RGCPD(list_of_name_path=list_of_name_path,\n",
    "           list_for_MI=list_for_MI,\n",
    "           tfreq=10, # <- subseasonal forecasting mode, all data will be aggregated to 10-day means\n",
    "           start_end_TVdate=('06-01', '08-31'), # <- defining target period \n",
    "           path_outmain=os.path.join(main_dir,'data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"./data/subseasonal_mode_JJA.png\", width = 400, height = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, if loading in monthly data, the exact same reasoning is followed. Where tfreq now stands for n-month means instead of n-day means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TVpath contains the xr.DataArray that is clustering beforehand, we can have a look at the spatial regions.\n",
    "rg.plot_df_clust()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.pp_precursors(detrend=True, anomaly=True, selbox=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option for pp_precursors to vary pre-processing of datasets by given a list as an argument:\n",
    "An example: detrend=[True, {'sm1':False, 'sm2':False}]. This input means that default argument is True, except the variables sm1 and sm2 got a different argument. The precursor names sm1 and sm2 should refer to the names given in list_of_name_path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.pp_TV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.pp_TV(detrend=True, anomaly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.fulltso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.traintest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.traintest(method='random_5')\n",
    "# rg._get_testyrs()[0] # see test years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.calc_corr_maps() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.plot_maps_corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.cluster_list_MI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.quick_view_labels(mean=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.get_ts_prec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation (BivariateMI) map, the timeseries are named according the format:\n",
    "{lag}..{region label}..{precursor name}, where precursor name is defined in list_of_name_path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test cross-validation and Response Variable mask handling\n",
    "\n",
    "- The different train-test fold organized in the first level index.\n",
    "- Each fold contains precursor timeseries that were extracted from only training data.\n",
    "- The Training data is specified by the TrainIsTrue mask.\n",
    "- The Response Variable mask defined the dates to predict \n",
    "- The RV_mask the anker for lag shifting the precursors.\n",
    "\n",
    "The last two columns should be always present. \n",
    "- The RV_mask is defined by the start_end_TVdate.\n",
    "- The TrainIsTrue is defined by the method for cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example lag shifting\n",
    "import func_models as fc_utils\n",
    "fc_utils.apply_shift_lag(rg.df_splits.loc[0].copy(), lag_i=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Discovery using Tigramite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.PCMCI_df_data(tigr_function_call='run_pcmci',\n",
    "                 kwrgs_tigr={'tau_min': 0,\n",
    "                             'tau_max': 1,\n",
    "                             'pc_alpha': 0.05,\n",
    "                             'max_conds_dim': 2,\n",
    "                             'max_combinations': 2,\n",
    "                             'max_conds_py': 2,\n",
    "                             'max_conds_px': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.PCMCI_get_links?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.PCMCI_get_links(var=rg.TV.name, alpha_level=.05)\n",
    "rg.df_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the left you see all the extraction precursor regions, on the right you see the regions which were found Conditionally Dependent (~Causal)\n",
    "rg.plot_maps_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated: rg.df_ParCorr_sum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality for Causal Inference\n",
    "(Define your own Conditional Independence tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrapper_PCMCI\n",
    "corr, pvals = wrapper_PCMCI.df_data_Parcorr(rg.df_data, \n",
    "                                            target='3ts',\n",
    "                                            keys=['1..2..sst'],\n",
    "                                            z_keys=['1..1..sst'],\n",
    "                                            z_lag=1)\n",
    "pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = rg.transform_df_data()\n",
    "\n",
    "df_z_removed = wrapper_PCMCI.df_data_remove_z(df_trans,\n",
    "                                              keys=['3ts'],\n",
    "                                              z=['1..2..sst'],\n",
    "                                              plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import func_models as fc_utils\n",
    "from stat_models_cont import ScikitModel\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "# choose type prediciton (continuous or probabilistic) by making comment #\n",
    "prediction = 'continuous'   \n",
    "# prediction = 'events' ; q = .66 # quantile threshold for event definition\n",
    "\n",
    "if prediction == 'continuous':\n",
    "    model = ScikitModel(Ridge, verbosity=0)\n",
    "    # You can also tune parameters by passing a list of values. Then GridSearchCV from sklearn will \n",
    "    # find the set of parameters that give the best mean score on all kfold test sets. \n",
    "    # below we pass a list of alpha's to tune the regularization.\n",
    "    alphas = list(np.concatenate([[1E-20],np.logspace(-5,0, 6), np.logspace(.01, 2.5, num=25)]))                       \n",
    "    kwrgs_model = {'scoringCV':'neg_mean_absolute_error',\n",
    "                   'kfold':5,\n",
    "                   'alpha':alphas} # large a, strong regul.\n",
    "elif prediction == 'events':\n",
    "    model = ScikitModel(LogisticRegressionCV, verbosity=0)\n",
    "    kwrgs_model = {'kfold':5,\n",
    "                   'scoring':'neg_brier_score'}\n",
    "\n",
    "    \n",
    "\n",
    "target_ts = rg.TV.RV_ts ; \n",
    "target_ts = (target_ts - target_ts.mean()) / target_ts.std()\n",
    "if prediction == 'events':\n",
    "    if q >= 0.5:\n",
    "        target_ts = (target_ts > target_ts.quantile(q)).astype(int)\n",
    "    elif q < .5:\n",
    "        target_ts = (target_ts < target_ts.quantile(q)).astype(int)\n",
    "    BSS = fc_utils.ErrorSkillScore(constant_bench=float(target_ts.mean())).BSS\n",
    "    score_func_list = [BSS, fc_utils.metrics.roc_auc_score]\n",
    "    \n",
    "elif prediction == 'continuous':\n",
    "    RMSE_SS = fc_utils.ErrorSkillScore(constant_bench=float(target_ts.mean())).RMSE\n",
    "    MAE_SS = fc_utils.ErrorSkillScore(constant_bench=float(target_ts.mean())).MAE\n",
    "    score_func_list = [RMSE_SS, fc_utils.corrcoef, MAE_SS]\n",
    "        \n",
    "    \n",
    "out = rg.fit_df_data_ridge(target=target_ts,\n",
    "                            keys=None,\n",
    "                            fcmodel=model,\n",
    "                            kwrgs_model=kwrgs_model,\n",
    "                            transformer=False,\n",
    "                            tau_min=1, tau_max=3)\n",
    "predict, weights, model_lags = out\n",
    "\n",
    "df_train_m, df_test_s_m, df_test_m, df_boot = fc_utils.get_scores(predict,\n",
    "                                                                 rg.df_data.iloc[:,-2:],\n",
    "                                                                 score_func_list,\n",
    "                                                                 n_boot = 100,\n",
    "                                                                 score_per_test=False,\n",
    "                                                                 blocksize=1,\n",
    "                                                                 rng_seed=1)\n",
    "lag = 1\n",
    "if prediction == 'events':\n",
    "    print(model.scikitmodel.__name__, '\\n', f'Test score at lag {lag}\\n',\n",
    "          'BSS {:.2f}\\n'.format(df_test_m.loc[0].loc[lag].loc['BSS']),\n",
    "          'AUC {:.2f}'.format(df_test_m.loc[0].loc[lag].loc['roc_auc_score']),\n",
    "          '\\nTrain score\\n',\n",
    "          'BSS {:.2f}\\n'.format(df_train_m.mean(0).loc[lag]['BSS']),\n",
    "          'AUC {:.2f}'.format(df_train_m.mean(0).loc[lag]['roc_auc_score']))\n",
    "elif prediction == 'continuous':\n",
    "    print(model.scikitmodel.__name__, '\\n', 'Test score\\n',\n",
    "              'RMSE {:.2f}\\n'.format(df_test_m.loc[0][lag]['RMSE']),\n",
    "              'MAE {:.2f}\\n'.format(df_test_m.loc[0][lag]['MAE']),\n",
    "              'corrcoef {:.2f}'.format(df_test_m.loc[0][lag]['corrcoef']),\n",
    "              '\\nTrain score\\n',\n",
    "              'RMSE {:.2f}\\n'.format(df_train_m.mean(0).loc[lag]['RMSE']),\n",
    "              'MAE {:.2f}\\n'.format(df_train_m.mean(0).loc[lag]['MAE']),\n",
    "              'corrcoef {:.2f}'.format(df_train_m.mean(0).loc[lag]['corrcoef']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_m.loc[0].plot.bar(rot=0, color=['blue', 'green', 'purple'], figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stat_models import plot_importances\n",
    "plot_importances(models_splits_lags=model_lags, lag=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match the retrieved timeseries of BivariateMI to the lag of forecasting \n",
    "Quick summary of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.list_for_MI[0].lags = np.array([0,1,2]) # update lags correlation map\n",
    "rg.calc_corr_maps()\n",
    "rg.cluster_list_MI()\n",
    "rg.get_ts_prec()\n",
    "rg.df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we now have a timeseries of the correlation maps lag 0 up to lag 2. Below, we can match these timeseries to lag-of-forecast by setting 'match_lag_region_to_lag_fc' to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.fit_df_data_ridge(match_lag_region_to_lag_fc=True,\n",
    "                    tau_min=0, tau_max=2)\n",
    "# Predicitons for lag 0, 1 and 2 using precursors extraction from correlation maps at lag 0, 1, 2, respecitvely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The arguments for using this package \n",
    "- Reproducible\n",
    "- Flexible\n",
    "- Time efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up your pipeline\n",
    "import func_models as fc_utils\n",
    "def pipeline(tfreq, start_end_TVdate):\n",
    "    rg = RGCPD(tfreq=tfreq, start_end_TVdate=start_end_TVdate)\n",
    "    rg.list_for_MI = [BivariateMI(name='sst_test', distance_eps=700)]\n",
    "    rg.pp_precursors() ; rg.pp_TV()\n",
    "    rg.traintest('random_5')\n",
    "    rg.calc_corr_maps() ; rg.cluster_list_MI()\n",
    "    rg.get_ts_prec()\n",
    "    prediction = rg.fit_df_data_ridge()[0]\n",
    "    out = fc_utils.get_scores(prediction,\n",
    "                              rg.df_data.iloc[:,-2:],\n",
    "                              None,\n",
    "                              n_boot = 0,\n",
    "                              score_per_test=False,\n",
    "                              blocksize=1)\n",
    "    df_train_m, df_test_s_m, df_test_m, df_boot = out\n",
    "    print(df_test_m.loc[0])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets choose a common timescale and target period for seasonal forecasts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(7, ('06-01','08-31')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the code handling all the anoying data-handling stuff, one can easily test different settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(15, ('07-01','08-31'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note a 30% increase in skill (MSE). The commonly used target window and timescale had no good predictability \n",
    "(likely has to due with dependence of temperature on end-of-summer soil moisture). \n",
    "\\\n",
    "\\\n",
    "When one codes a pipeline for 1 goal (7 day-mean forecast, JJA summer). He/she is restricted by the investment when testing other plausible hypothesis. With this Python package, users are freed from the coding time-investment and can spend more time on testing different hypthesis very efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A non-extensive list of options to test:\n",
    "- Different timescales\n",
    "- Different target window(s)\n",
    "- Different precursors\n",
    "- Different precursor extraction methods ((partial) correlation, EOF, ...)\n",
    "- Different statistical model feature selection methods\n",
    "- Different statistical models / tuning methods\n",
    "- Different train-test splits\n",
    "- Different definitions for the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (old) Forecasting pipeline 2 \n",
    "Used for MWR paper https://doi.org/10.1175/MWR-D-19-0409.1\n",
    "\n",
    "There is some multiprocessing based on Python's standard 'concurrent futures' module. This only works when run script is run in one go. Will not work another time. Has to do with the running the code as the __main__ file or something.. (don't know the details). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.store_df_PCMCI() # storing timeseries in .h5 format\n",
    "path_df_data = rg.path_df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load in the data, including info on the causal links. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_fc import fcev\n",
    "import valid_plots as dfplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = fcev(path_data=path_df_data, n_cpu=1, causal=True)\n",
    "fc.df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.get_TV(kwrgs_events=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define statmodel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.fit_models?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.fit_models(lead_max=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_experiments = {}       \n",
    "fc.perform_validation(n_boot=100, blocksize='auto', \n",
    "                              threshold_pred=(1.5, 'times_clim'))\n",
    "dict_experiments['test'] = fc.dict_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_folder, filename = fc._print_sett(list_of_fc=[fc])\n",
    "store=True\n",
    "dict_all = dfplots.merge_valid_info([fc], store=store)\n",
    "if store:\n",
    "    dict_merge_all = functions_pp.load_hdf5(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kwrgs = {'wspace':0.25, 'col_wrap':3} #, 'threshold_bin':fc.threshold_pred}\n",
    "met = ['AUC-ROC', 'AUC-PR', 'BSS', 'Rel. Curve', 'Precision', 'Accuracy']\n",
    "expers = list(dict_experiments.keys())\n",
    "line_dim = 'model'\n",
    "\n",
    "\n",
    "fig = dfplots.valid_figures(dict_merge_all, #expers=expers, #models=models,\n",
    "                          line_dim=line_dim, \n",
    "                          group_line_by=None,  \n",
    "                          met=met, **kwrgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
